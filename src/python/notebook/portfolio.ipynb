{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61559655-1cfd-477c-b3a2-9cef1d1017d9",
   "metadata": {},
   "source": [
    "# Portfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cfe4ec-ec9d-4e12-927b-5d9174f02bed",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e86b63-9daf-4393-a373-e9d718ddb341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4eacf9-ecf6-4f27-868c-713662be9d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs\n",
    "\n",
    "device = torch.device('cpu')\n",
    "MODEL_PTH_PATH = os.path.abspath('../../../dataset/nikkei_mid_small_cap-i5r5ma50/nikkei_mid_small_cap-i5r5ma50-1719447843.pth')\n",
    "IMAGE_FOLDER = os.path.abspath('../../../dataset/nikkei_mid_small_cap-i5r5ma50/input')\n",
    "RETURN_FOLDER = os.path.abspath('../../../dataset/nikkei_mid_small_cap-i5r5ma50/return')\n",
    "\n",
    "# get the stock ticker from the folder\n",
    "RAW_DATA_FOLDER_PATH = os.path.abspath('../../../dataset/market_data/output/nikkei_mid_small_cap')\n",
    "# get the date from the index data\n",
    "INDEX_DATA = 'INDEX_DAILY_NIKKEI_MID_SMALL_CAP.csv'\n",
    "START_DATE = '2014-04-01'\n",
    "RETURN_DATA_TYPE = 'r5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb9d000-c0b6-4318-8e34-600dcf2ea157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model and predict function\n",
    "\n",
    "# copy from cnn_model\n",
    "class I5_CNNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, (5, 3), padding=(2, 1), stride=(1, 1), dilation=(1, 1))\n",
    "        self.conv2 = nn.Conv2d(64, 128, (5, 3), padding=(2, 1), stride=(1, 1), dilation=(1, 1))\n",
    "        self.bn1 = nn.BatchNorm2d(64, affine=True)\n",
    "        self.bn2 = nn.BatchNorm2d(128, affine=True)\n",
    "        self.pool = nn.MaxPool2d((2, 1))\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(15360, 3)\n",
    "        self.init_weights(self.conv1)\n",
    "        self.init_weights(self.conv2)\n",
    "        self.init_weights(self.fc)\n",
    "        \n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.leaky_relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.leaky_relu(self.bn2(self.conv2(x))))\n",
    "        x = self.dropout(x.view(x.shape[0], -1))\n",
    "        x = self.fc(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "def load_model(\n",
    "        _model_pth_path: str,\n",
    "    ):\n",
    "    _model = I5_CNNet().to(device)\n",
    "    state_dict = torch.load(_model_pth_path, map_location=device)\n",
    "    _model.load_state_dict(state_dict['model_state_dict'])\n",
    "    _model.eval() # need this line to fix the value\n",
    "    return _model\n",
    "\n",
    "# return an array: [p|0, p|1, p|2]\n",
    "def predict(\n",
    "        _model,\n",
    "        _image,\n",
    "        _transformer,\n",
    "    ):\n",
    "    with torch.no_grad():\n",
    "        _image_tensor = _transformer(_image)\n",
    "        _image_tensor.unsqueeze_(0)\n",
    "        output = _model(_image_tensor)\n",
    "    return output.tolist()[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95111378-8342-4174-9cc7-62416976c58b",
   "metadata": {},
   "source": [
    "### Generate Portfolio Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f473619-dc05-49f9-ace6-c64207f016a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. get a list of date\n",
    "\n",
    "df = pd.read_csv(RAW_DATA_FOLDER_PATH + \"/\" + INDEX_DATA, parse_dates=['date'])\n",
    "df = df.loc[df['date'] > START_DATE].filter(regex='date') # get the date only\n",
    "df = df.sort_values(by=['date'], ascending=True).reset_index(drop=True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1daaacc-5a41-45fb-9258-51b013b1fcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. get stocks list from raw data file name\n",
    "stocks = []\n",
    "for source_file in os.listdir(RAW_DATA_FOLDER_PATH):\n",
    "    if source_file == INDEX_DATA:\n",
    "        # ignoring index data, although the CONSTITUENTS marks should already filter it\n",
    "        continue\n",
    "    if source_file.startswith('CONSTITUENTS'):\n",
    "        ticker = source_file.replace('CONSTITUENTS_DAILY_', '').replace('.csv', '')\n",
    "        stocks.append(ticker)\n",
    "\n",
    "print(\"Total stocks: #\" + str(len(stocks)))\n",
    "print(\"eg: \" + str(stocks[0:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac6c5c5-c28c-49be-841c-a3df590a88a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. loop stocks and get prediction using the trained model\n",
    "\n",
    "model = load_model(MODEL_PTH_PATH)\n",
    "transformer = transforms.Compose([transforms.Grayscale(), transforms.ToTensor()])\n",
    "\n",
    "data = {}\n",
    "\n",
    "for stock in tqdm(stocks):\n",
    "    try:\n",
    "        return_df = pd.read_pickle(RETURN_FOLDER + '/RETURN_' + stock + '.pkl')\n",
    "    except:\n",
    "        print(\"Return data not found: \" + stock)\n",
    "        continue\n",
    "    results = []\n",
    "    for index, date in tqdm(df['date'].items()):\n",
    "        try:\n",
    "            image = Image.open(IMAGE_FOLDER + f'/{stock}_{date.date()}.png')\n",
    "            prediction = predict(model, image, transformer)\n",
    "            return_value = return_df.loc[return_df['date'] == str(date.date())][RETURN_DATA_TYPE]\n",
    "            prediction.append((float(return_value.iloc[0])))\n",
    "            results.append(prediction)\n",
    "        except:\n",
    "            print('error on: ' + stock + ' ' + str(date.date()))\n",
    "            results.append(None)\n",
    "    data[stock] = results\n",
    "\n",
    "df = df.assign(**data)\n",
    "\n",
    "df.to_csv(f'{MODEL_PTH_PATH.split(\"\\\\\")[-1].replace('.pth', '')}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48940b3c-114b-469f-9f33-04462a06fcf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
