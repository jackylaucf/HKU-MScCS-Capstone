{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1571157-e384-47c4-b701-fbca0701d138",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cee11a-eae9-4d61-b61e-739ff480b8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import logging\n",
    "time_now = int(time.time())\n",
    "logger = logging.getLogger('')\n",
    "logging.basicConfig(filename=f'portfolio_analysys.{time_now}.log', encoding='utf-8', level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3f4db2-6f69-4e77-ab72-89ebdc1e508c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop dataframe to get portfolio result\n",
    "def portfolio_analysis(\n",
    "        _data: pd.DataFrame,\n",
    "        initial_capital = 200000,\n",
    "        threshold = 0.7,\n",
    "        logging = False,\n",
    "        skipping = 5,\n",
    "        _enable_short = True,\n",
    "    ):\n",
    "    if logging:\n",
    "        logger.info(f'-----------------------')\n",
    "        logger.info(f'-----Start Logging-----')\n",
    "        logger.info(f'-----------------------')\n",
    "    # meta = []\n",
    "    dates = [_data['date'][0] - pd.tseries.offsets.Day()]\n",
    "    capitals = [initial_capital]\n",
    "    long_counts = [0]\n",
    "    short_counts = [0]\n",
    "    current = initial_capital\n",
    "    for index, row in _data.iterrows():\n",
    "        if index % skipping != 0:\n",
    "            continue\n",
    "        s_return = 0\n",
    "        s_count = 0\n",
    "        l_return = 0\n",
    "        l_count = 0\n",
    "        for i, _v in row.items():\n",
    "            if (i == 'date'):\n",
    "                if logging:\n",
    "                    logger.info(f'')\n",
    "                    logger.info(f'---{_v}---')\n",
    "                continue\n",
    "            if (type(_v) is not str):\n",
    "                continue\n",
    "            # parse array-format-string to actual array\n",
    "            v = _v[1:-1].split(',')\n",
    "            if (type(v) is list):\n",
    "                # short\n",
    "                if float(v[0]) >= threshold:\n",
    "                    if logging:\n",
    "                        logger.info(f'{i} is included in [Short] - p:{v[0]}, r:{v[3]} ')\n",
    "                    s_return = (s_return * s_count + float(v[3])) / (s_count + 1)\n",
    "                    s_count += 1\n",
    "                # long\n",
    "                if float(v[2]) >= threshold:\n",
    "                    if logging:\n",
    "                        logger.info(f'{i} is included in [Long] - p:{v[2]}, r:{v[3]} ')\n",
    "                    l_return = (l_return * l_count + float(v[3])) / (l_count + 1)\n",
    "                    l_count += 1\n",
    "        # skip if no short or long\n",
    "        if (l_count == 0 or (s_count == 0 and _enable_short)):\n",
    "            if logging:\n",
    "                logger.info(f'Not doing anything: l/s count: {l_count} / {s_count}, _enable_short: {str(_enable_short)}')\n",
    "                logger.info(f'Final Capital: {current}')\n",
    "            dates.append(row['date'])\n",
    "            long_counts.append(0)\n",
    "            short_counts.append(0)\n",
    "            capitals.append(current)\n",
    "            continue\n",
    "        l_capital = (current / 2) * (1 + l_return) if _enable_short else current * (1 + l_return)\n",
    "        s_capital = (current / 2) * (1 - s_return) if _enable_short else 0\n",
    "        if logging:\n",
    "            logger.info(f'current: {current}')\n",
    "            logger.info(f'l_return: {l_return}')\n",
    "            logger.info(f's_return: {s_return}')\n",
    "            logger.info(f'l_capital: {l_capital}')\n",
    "            logger.info(f's_capital: {s_capital}')\n",
    "        current = l_capital + s_capital\n",
    "        # print('doing trade on ' + str(row['date']))\n",
    "        # print('current: ' + str(current))\n",
    "        dates.append(row['date'])\n",
    "        capitals.append(current)\n",
    "        long_counts.append(l_count)\n",
    "        short_counts.append(s_count)\n",
    "        if logging:\n",
    "            logger.info(f'Final Capital: {current}')\n",
    "\n",
    "    data = {\n",
    "        'date': np.array(dates),\n",
    "        'capital': np.array(capitals),\n",
    "        'long_count': np.array(long_counts),\n",
    "        'short_count': np.array(short_counts),\n",
    "    }\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7a8d0c-cb3a-4586-8c26-bd9918243d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# long-short\n",
    "MODEL_DATA_FOLDER_PATH = os.path.abspath('./portfolio')\n",
    "initial_capital = 200000\n",
    "enable_short = True\n",
    "logging = False\n",
    "\n",
    "for source_file in tqdm(os.listdir(MODEL_DATA_FOLDER_PATH)):\n",
    "    if source_file.endswith('.csv'):\n",
    "        file_name = source_file.replace('.csv', '')\n",
    "        # print('Current in: ' + file_name)\n",
    "        skipping = 60 if 'r60ma' in file_name else 20 if 'r20ma' in file_name else 5\n",
    "        # print('skipping: ' + str(skipping))\n",
    "        df = pd.read_csv(MODEL_DATA_FOLDER_PATH + '/' + source_file, parse_dates=['date'])\n",
    "        for threshold in [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8]:\n",
    "            portfolio_result = portfolio_analysis(df, initial_capital, threshold, logging, skipping, enable_short)\n",
    "            ts = pd.Series(portfolio_result['capital'], index=portfolio_result['date'])\n",
    "            ts.plot()\n",
    "            plt.savefig(MODEL_DATA_FOLDER_PATH + '/output/' + file_name + '-' + str(threshold) + '.png')\n",
    "            plt.clf()\n",
    "            pd.DataFrame.from_dict(portfolio_result).to_csv(MODEL_DATA_FOLDER_PATH + '/output/' + file_name + '-' + str(threshold) + 'portfolio_result.csv')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7a6f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# long only\n",
    "MODEL_DATA_FOLDER_PATH = os.path.abspath('./portfolio')\n",
    "initial_capital = 200000\n",
    "enable_short = False\n",
    "logging = False\n",
    "\n",
    "for source_file in tqdm(os.listdir(MODEL_DATA_FOLDER_PATH)):\n",
    "    if source_file.endswith('.csv') and source_file.startswith('nikkei_mid_small_cap-i5r5'):\n",
    "        file_name = source_file.replace('.csv', '')\n",
    "        # print('Current in: ' + file_name)\n",
    "        skipping = 60 if 'r60ma' in file_name else 20 if 'r20ma' in file_name else 5\n",
    "        # print('skipping: ' + str(skipping))\n",
    "        df = pd.read_csv(MODEL_DATA_FOLDER_PATH + '/' + source_file, parse_dates=['date'])\n",
    "        for threshold in [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8]:\n",
    "            portfolio_result = portfolio_analysis(df, initial_capital, threshold, logging, skipping, enable_short)\n",
    "            ts = pd.Series(portfolio_result['capital'], index=portfolio_result['date'])\n",
    "            # ts.plot(yticks=[0, 100000, 200000, 500000]);\n",
    "            ts.plot()\n",
    "            plt.savefig(MODEL_DATA_FOLDER_PATH + '/output/' + file_name + '-' + str(threshold) + '-long.png')\n",
    "            plt.clf()\n",
    "            pd.DataFrame.from_dict(portfolio_result).to_csv(MODEL_DATA_FOLDER_PATH + '/output/' + file_name + '-' + str(threshold) + 'portfolio_result_long.csv')\n",
    "            \n",
    "            # long count\n",
    "            #ts = pd.Series(portfolio_result['long_count'], index=portfolio_result['date'])\n",
    "            #ts.plot()\n",
    "            #plt.savefig(MODEL_DATA_FOLDER_PATH + '/output/' + file_name + '-' + str(threshold) + '-long_count.png')\n",
    "            #plt.clf()\n",
    "            #pd.DataFrame.from_dict(portfolio_result).to_csv(MODEL_DATA_FOLDER_PATH + '/output/' + file_name + '-' + str(threshold) + 'portfolio_result_long.csv')\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7f5ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hsi sector only\n",
    "# long only\n",
    "MODEL_DATA_FOLDER_PATH = os.path.abspath('./portfolio')\n",
    "initial_capital = 200000\n",
    "enable_short = False\n",
    "logging = False\n",
    "\n",
    "sector_mapping = pd.read_csv('./hsi_sector_mapping.csv')\n",
    "sector = 'Utilities'\n",
    "\n",
    "tickers = sector_mapping.loc[sector_mapping['Merged Grouping'] == sector]['Ticker'].to_list()\n",
    "print(tickers)\n",
    "\n",
    "# add the necessary column name\n",
    "tickers.insert(0, 'date')\n",
    "\n",
    "for source_file in tqdm(os.listdir(MODEL_DATA_FOLDER_PATH)):\n",
    "    if source_file.endswith('.csv') and source_file.startswith('hsi-i5r5'):\n",
    "        file_name = source_file.replace('.csv', '')\n",
    "        # print('Current in: ' + file_name)\n",
    "        skipping = 60 if 'r60ma' in file_name else 20 if 'r20ma' in file_name else 5\n",
    "        # print('skipping: ' + str(skipping))\n",
    "        df = pd.read_csv(MODEL_DATA_FOLDER_PATH + '/' + source_file, parse_dates=['date'])\n",
    "        # filtering non-sector column\n",
    "        df = df[tickers]\n",
    "        for threshold in [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8]:\n",
    "            portfolio_result = portfolio_analysis(df, initial_capital, threshold, logging, skipping, enable_short)\n",
    "            ts = pd.Series(portfolio_result['capital'], index=portfolio_result['date'])\n",
    "            # ts.plot(yticks=[0, 100000, 200000, 500000]);\n",
    "            ts.plot()\n",
    "            plt.savefig(MODEL_DATA_FOLDER_PATH + '/output/' + file_name + '-' + str(threshold) + '-long-' + sector + '.png')\n",
    "            plt.clf()\n",
    "            pd.DataFrame.from_dict(\n",
    "                portfolio_result).to_csv(\n",
    "                    MODEL_DATA_FOLDER_PATH +\n",
    "                    '/output/' +\n",
    "                    file_name +\n",
    "                    '-' +\n",
    "                    str(threshold) +\n",
    "                    'portfolio_result_long-' +\n",
    "                    sector +\n",
    "                    '.csv')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66ecf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hsi sector only\n",
    "# long short\n",
    "MODEL_DATA_FOLDER_PATH = os.path.abspath('./portfolio')\n",
    "initial_capital = 200000\n",
    "enable_short = True\n",
    "logging = False\n",
    "\n",
    "sector_mapping = pd.read_csv('./hsi_sector_mapping.csv')\n",
    "sector = 'Real Estate'\n",
    "\n",
    "tickers = sector_mapping.loc[sector_mapping['Merged Grouping'] == sector]['Ticker'].to_list()\n",
    "\n",
    "# add the necessary column name\n",
    "tickers.insert(0, 'date')\n",
    "\n",
    "for source_file in tqdm(os.listdir(MODEL_DATA_FOLDER_PATH)):\n",
    "    if source_file.endswith('.csv') and source_file.startswith('hsi-i5r5'):\n",
    "        file_name = source_file.replace('.csv', '')\n",
    "        # print('Current in: ' + file_name)\n",
    "        skipping = 60 if 'r60ma' in file_name else 20 if 'r20ma' in file_name else 5\n",
    "        # print('skipping: ' + str(skipping))\n",
    "        df = pd.read_csv(MODEL_DATA_FOLDER_PATH + '/' + source_file, parse_dates=['date'])\n",
    "        # filtering non-sector column\n",
    "        df = df[tickers]\n",
    "        for threshold in [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8]:\n",
    "            portfolio_result = portfolio_analysis(df, initial_capital, threshold, logging, skipping, enable_short)\n",
    "            ts = pd.Series(portfolio_result['capital'], index=portfolio_result['date'])\n",
    "            # ts.plot(yticks=[0, 100000, 200000, 500000]);\n",
    "            ts.plot()\n",
    "            plt.savefig(MODEL_DATA_FOLDER_PATH + '/output/' + file_name + '-' + str(threshold) + '-' + sector + '.png')\n",
    "            plt.clf()\n",
    "            pd.DataFrame.from_dict(\n",
    "                portfolio_result).to_csv(\n",
    "                    MODEL_DATA_FOLDER_PATH +\n",
    "                    '/output/' +\n",
    "                    file_name +\n",
    "                    '-' +\n",
    "                    str(threshold) +\n",
    "                    'portfolio_result-' +\n",
    "                    sector +\n",
    "                    '.csv')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ecb5d7-5ef5-4a28-925e-c5d04465aa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this to inspect one csv\n",
    "DATA_PATH = os.path.abspath('./portfolio/nifty_midcap_100-i20r5ma50-1720842029.csv')\n",
    "df = pd.read_csv(DATA_PATH, parse_dates=['date'])\n",
    "threshold = 0.5\n",
    "logging = True\n",
    "skipping = 5\n",
    "enable_short = False\n",
    "\n",
    "portfolio_result = portfolio_analysis(df, 200000, threshold, logging, skipping, enable_short)\n",
    "ts = pd.Series(portfolio_result['capital'], index=portfolio_result['date'])\n",
    "ts.plot();\n",
    "plt.savefig('./inspecting_model.png')\n",
    "plt.clf()\n",
    "pd.DataFrame.from_dict(portfolio_result).to_csv('./inspecting_model_portfolio_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69adb31-68df-40ba-920c-66565e782da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate chart/data for index\n",
    "index_path = '../../../dataset/market_data/output/kosdaq_150/INDEX_DAILY_KOSDAQ_150.csv'\n",
    "output_name = 'kosdaq_150'\n",
    "START_DATE = '2014-04-01'\n",
    "CAPITAL = 200000\n",
    "\n",
    "index_df = pd.read_csv(index_path, parse_dates=['date'])\n",
    "index_df = index_df.drop(columns=['adj_close', 'volume', 'high', 'low'])\n",
    "index_df = index_df.dropna(how='any')\n",
    "index_df = index_df.loc[index_df['date'] > START_DATE]\n",
    "index_df = index_df.sort_values(by=['date'], ascending=True).reset_index(drop=True)\n",
    "\n",
    "dates = [index_df['date'][0] - pd.tseries.offsets.Day()]\n",
    "capitals = [float(CAPITAL)]\n",
    "\n",
    "base = index_df['open'][0]\n",
    "\n",
    "for index, row in index_df.iterrows():\n",
    "    dates.append(row['date'])\n",
    "    capitals.append(float(CAPITAL * row['close'] / base))\n",
    "\n",
    "pd.DataFrame.from_dict({\n",
    "    'date': dates,\n",
    "    'capital': capitals\n",
    "}).to_csv('./index/' + output_name + '.csv')\n",
    "\n",
    "ts = pd.Series(np.array(capitals), index=np.array(dates))\n",
    "ts.plot()\n",
    "plt.savefig('./index/' + output_name + '.png')\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d706de1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
