{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07f582dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numbers\n",
    "import os\n",
    "import pandas as pd\n",
    "import platform\n",
    "import shutil\n",
    "import time\n",
    "import torch\n",
    "import torch.cuda\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from collections import Counter\n",
    "from datetime import date\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from torchvision.datasets import ImageFolder\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "189a3bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "CUDA_ENABLED = torch.cuda.is_available()\n",
    "if CUDA_ENABLED:\n",
    "    print(torch.cuda.get_device_name())\n",
    "else:\n",
    "    print(platform.processor())\n",
    "device = torch.device('cuda' if CUDA_ENABLED else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "603824ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28139274c7674610a003baa888367204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/594426 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb16e088fa4f44739fcf465a26077690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/148607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7c62b90cba048f9893dadf79797a71c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/588557 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7fab989f551418f96f0ea0845cd3c31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/147140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_training_space(market_index: str, lookback_days: int, forecast_days: int, ma_line: int, margins: tuple):\n",
    "    workspace = os.path.abspath(f'../../../training/{market_index}/i{lookback_days}-r{forecast_days}-ma{ma_line}')\n",
    "    os.makedirs(workspace, exist_ok=True)\n",
    "    \n",
    "    train_folder_path = os.path.join(workspace, 'input/train')\n",
    "    test_folder_path = os.path.join(workspace, 'input/test')\n",
    "    for cls_label in (0, 1, 2):\n",
    "        os.makedirs(os.path.join(train_folder_path, str(cls_label)), exist_ok=True)\n",
    "        os.makedirs(os.path.join(test_folder_path, str(cls_label)), exist_ok=True)\n",
    "    \n",
    "    graph_data_folder = f'../../../dataset/ohlc_graphs/{market_index}/i{lookback_days}-ma{ma_line}'\n",
    "    train_files, test_files = train_test_split(os.listdir(graph_data_folder), test_size=0.2)\n",
    "    \n",
    "    return_data = None\n",
    "    for item in os.scandir(f'../../../dataset/returns/{market_index}'):\n",
    "        if item.path.endswith('.pkl'):\n",
    "            df = pd.read_pickle(os.path.abspath(item.path))\n",
    "            return_data = pd.concat([return_data, df], ignore_index=True) if isinstance(return_data, pd.DataFrame) else df\n",
    "    \n",
    "    return_data = return_data.set_index(['date', 'ticker'])\n",
    "    for file in tqdm(train_files):\n",
    "        ticker, dt = file.replace('.png', '').split('_')\n",
    "        return_val = return_data.loc[dt, ticker][f'r{forecast_days}']\n",
    "        if isinstance(return_val, numbers.Number) and not math.isnan(return_val):\n",
    "            if return_val < margins[0]:\n",
    "                label = 0\n",
    "            elif return_val > margins[1]:\n",
    "                label = 2\n",
    "            else:\n",
    "                label = 1\n",
    "            src_path = os.path.join(graph_data_folder, file)\n",
    "            target_path = os.path.join(train_folder_path, str(label), file)\n",
    "            shutil.copy(src_path, target_path)\n",
    "\n",
    "    for file in tqdm(test_files):\n",
    "        ticker, dt = file.replace('.png', '').split('_')\n",
    "        return_val = return_data.loc[dt, ticker][f'r{forecast_days}']\n",
    "        if isinstance(return_val, numbers.Number) and not math.isnan(return_val):\n",
    "            if return_val < margins[0]:\n",
    "                label = 0\n",
    "            elif return_val > margins[1]:\n",
    "                label = 2\n",
    "            else:\n",
    "                label = 1\n",
    "            src_path = os.path.join(graph_data_folder, file)\n",
    "            target_path = os.path.join(test_folder_path, str(label), file)\n",
    "            shutil.copy(src_path, target_path)\n",
    "\n",
    "# Moving graphs to the /training folder\n",
    "create_training_space('nikkei_mid_small_cap', 20, 5, 50, (-0.033320, 0.044304))\n",
    "create_training_space('nikkei_mid_small_cap', 60, 5, 50, (-0.054173, 0.092287))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab61faed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class I5_CNNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, (5, 3), padding=(2, 1), stride=(1, 1), dilation=(1, 1))\n",
    "        self.conv2 = nn.Conv2d(64, 128, (5, 3), padding=(2, 1), stride=(1, 1), dilation=(1, 1))\n",
    "        self.bn1 = nn.BatchNorm2d(64, affine=True)\n",
    "        self.bn2 = nn.BatchNorm2d(128, affine=True)\n",
    "        self.pool = nn.MaxPool2d((2, 1))\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(15360, 3)\n",
    "        self.init_weights(self.conv1)\n",
    "        self.init_weights(self.conv2)\n",
    "        self.init_weights(self.fc)\n",
    "        \n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.leaky_relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.leaky_relu(self.bn2(self.conv2(x))))\n",
    "        x = self.dropout(x.view(x.shape[0], -1))\n",
    "        x = self.fc(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "class I20_CNNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, (5, 3), padding=(3, 1), stride=(3, 1), dilation=(2, 1))\n",
    "        self.conv2 = nn.Conv2d(64, 128, (5, 3), padding=(3, 1), stride=(1, 1), dilation=(1, 1))\n",
    "        self.conv3 = nn.Conv2d(128, 256, (5, 3), padding=(2, 1), stride=(1, 1), dilation=(1, 1))\n",
    "        self.bn1 = nn.BatchNorm2d(64, affine=True)\n",
    "        self.bn2 = nn.BatchNorm2d(128, affine=True)\n",
    "        self.bn3 = nn.BatchNorm2d(256, affine=True)\n",
    "        self.pool = nn.MaxPool2d((2, 1))\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(46080, 3)\n",
    "        self.init_weights(self.conv1)\n",
    "        self.init_weights(self.conv2)\n",
    "        self.init_weights(self.conv3)\n",
    "        self.init_weights(self.fc)\n",
    "        \n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.leaky_relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.leaky_relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.leaky_relu(self.bn3(self.conv3(x))))\n",
    "        x = self.dropout(x.view(x.shape[0], -1))\n",
    "        x = self.fc(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "class I60_CNNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, (5, 3), padding=(3, 1), stride=(3, 1), dilation=(3, 1))\n",
    "        self.conv2 = nn.Conv2d(64, 128, (5, 3), padding=(2, 1), stride=(1, 1), dilation=(1, 1))\n",
    "        self.conv3 = nn.Conv2d(128, 256, (5, 3), padding=(2, 1), stride=(1, 1), dilation=(1, 1))\n",
    "        self.conv4 = nn.Conv2d(256, 512, (5, 3), padding=(2, 1), stride=(1, 1), dilation=(1, 1))\n",
    "        self.bn1 = nn.BatchNorm2d(64, affine=True)\n",
    "        self.bn2 = nn.BatchNorm2d(128, affine=True)\n",
    "        self.pool = nn.MaxPool2d((2, 1))\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(15360, 3)\n",
    "        self.init_weights(self.conv1)\n",
    "        self.init_weights(self.conv2)\n",
    "        self.init_weights(self.fc)\n",
    "        \n",
    "    def init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.leaky_relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.leaky_relu(self.bn2(self.conv2(x))))\n",
    "        x = self.dropout(x.view(x.shape[0], -1))\n",
    "        x = self.fc(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "863bf7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start epoch 0\n",
      "[Epoch Train 1] - Avg Loss = 1.1201624910629124 - Correct = 163201 - Accuracy = 0.36558544835465157 - f1 = 0.3652343779070073\n",
      "[Epoch Valid 1] - Avg Loss = 1.0949459677611766 - Correct = 56560 - Accuracy = 0.3800998635780193 - f1 = 0.37010105240739843\n",
      "Start epoch 1\n",
      "[Epoch Train 2] - Avg Loss = 1.1139425636363138 - Correct = 165446 - Accuracy = 0.3706144575614346 - f1 = 0.3703868195063156\n",
      "[Epoch Valid 2] - Avg Loss = 1.091649971229704 - Correct = 56734 - Accuracy = 0.38126919484150185 - f1 = 0.3778803780078035\n",
      "Start epoch 2\n",
      "[Epoch Train 3] - Avg Loss = 1.1098263080855575 - Correct = 166317 - Accuracy = 0.3725655787280751 - f1 = 0.37234475517126153\n",
      "[Epoch Valid 3] - Avg Loss = 1.0902618649491747 - Correct = 56764 - Accuracy = 0.38147080368003333 - f1 = 0.37957820432962425\n",
      "Start epoch 3\n",
      "[Epoch Train 4] - Avg Loss = 1.1080335620961606 - Correct = 165755 - Accuracy = 0.3713066463564884 - f1 = 0.3711368457328217\n",
      "[Epoch Valid 4] - Avg Loss = 1.0900471156153921 - Correct = 56956 - Accuracy = 0.3827611002466348 - f1 = 0.37935545567984374\n",
      "Start epoch 4\n",
      "[Epoch Train 5] - Avg Loss = 1.104722988065503 - Correct = 167076 - Accuracy = 0.37426580945767346 - f1 = 0.37403457379948163\n",
      "[Epoch Valid 5] - Avg Loss = 1.0889074201739664 - Correct = 57021 - Accuracy = 0.3831979193967864 - f1 = 0.3809351107269994\n",
      "Start epoch 5\n",
      "[Epoch Train 6] - Avg Loss = 1.1029834482784664 - Correct = 167103 - Accuracy = 0.3743262919737461 - f1 = 0.3742529989029686\n",
      "[Epoch Valid 6] - Avg Loss = 1.0887174158391517 - Correct = 56782 - Accuracy = 0.3815917689831522 - f1 = 0.3782639990653831\n",
      "Start epoch 6\n",
      "[Epoch Train 7] - Avg Loss = 1.1008239906588826 - Correct = 167786 - Accuracy = 0.3758562756210658 - f1 = 0.37562989516166123\n",
      "[Epoch Valid 7] - Avg Loss = 1.0878911510378968 - Correct = 57094 - Accuracy = 0.3836885009038796 - f1 = 0.37789032481688817\n",
      "Start epoch 7\n",
      "[Epoch Train 8] - Avg Loss = 1.0992599781089967 - Correct = 168385 - Accuracy = 0.37719809144060396 - f1 = 0.3769994748852297\n",
      "[Epoch Valid 8] - Avg Loss = 1.087907062556758 - Correct = 57018 - Accuracy = 0.38317775851293323 - f1 = 0.3640652125060544\n",
      "Start epoch 8\n",
      "[Epoch Train 9] - Avg Loss = 1.0976403746241277 - Correct = 168625 - Accuracy = 0.3777357138056943 - f1 = 0.3775510472113673\n",
      "[Epoch Valid 9] - Avg Loss = 1.0868516867261249 - Correct = 57071 - Accuracy = 0.38353393412767217 - f1 = 0.37400567931151135\n",
      "Start epoch 9\n",
      "[Epoch Train 10] - Avg Loss = 1.0965606037766562 - Correct = 168357 - Accuracy = 0.3771353688313434 - f1 = 0.37697064154370247\n",
      "[Epoch Valid 10] - Avg Loss = 1.0864691173630547 - Correct = 57064 - Accuracy = 0.38348689206534814 - f1 = 0.381661145682622\n",
      "Start epoch 10\n",
      "[Epoch Train 11] - Avg Loss = 1.0953004219389837 - Correct = 169544 - Accuracy = 0.37979435944535295 - f1 = 0.37956061246482836\n",
      "[Epoch Valid 11] - Avg Loss = 1.0864622772303718 - Correct = 57044 - Accuracy = 0.38335248617299383 - f1 = 0.38307280120123294\n",
      "Start epoch 11\n",
      "[Epoch Train 12] - Avg Loss = 1.093914130993119 - Correct = 169696 - Accuracy = 0.3801348536099102 - f1 = 0.37997243533081754\n",
      "[Epoch Valid 12] - Avg Loss = 1.0865002198149598 - Correct = 57249 - Accuracy = 0.3847301465696256 - f1 = 0.37592644489313615\n",
      "Start epoch 12\n",
      "[Epoch Train 13] - Avg Loss = 1.0934013950578663 - Correct = 170017 - Accuracy = 0.38085392352321856 - f1 = 0.3806913081398655\n",
      "[Epoch Valid 13] - Avg Loss = 1.0866796825840261 - Correct = 57084 - Accuracy = 0.38362129795770245 - f1 = 0.3639240900918943\n",
      "Start epoch 13\n",
      "[Epoch Train 14] - Avg Loss = 1.092064873101788 - Correct = 170467 - Accuracy = 0.381861965457763 - f1 = 0.38170060250051513\n",
      "[Epoch Valid 14] - Avg Loss = 1.086624265639616 - Correct = 56973 - Accuracy = 0.382875345255136 - f1 = 0.37730776661881743\n",
      "Start epoch 14\n",
      "[Epoch Train 15] - Avg Loss = 1.0912791657680219 - Correct = 170757 - Accuracy = 0.38251159248224725 - f1 = 0.3823625697008716\n",
      "[Epoch Valid 15] - Avg Loss = 1.0871966277743248 - Correct = 56945 - Accuracy = 0.38268717700583993 - f1 = 0.36035902010295584\n",
      "Start epoch 15\n",
      "[Epoch Train 16] - Avg Loss = 1.090327052006481 - Correct = 171469 - Accuracy = 0.3841065388320154 - f1 = 0.3839114018010028\n",
      "[Epoch Valid 16] - Avg Loss = 1.0858435695374309 - Correct = 57287 - Accuracy = 0.3849855177650988 - f1 = 0.3665562518054015\n",
      "Start epoch 16\n",
      "[Epoch Train 17] - Avg Loss = 1.089717290509458 - Correct = 171830 - Accuracy = 0.3849152124728389 - f1 = 0.3846359339304081\n",
      "[Epoch Valid 17] - Avg Loss = 1.0860570248917885 - Correct = 57138 - Accuracy = 0.3839841938670591 - f1 = 0.3666487658883623\n",
      "Start epoch 17\n",
      "[Epoch Train 18] - Avg Loss = 1.089384648846377 - Correct = 171585 - Accuracy = 0.3843663896418091 - f1 = 0.3840252282830381\n",
      "[Epoch Valid 18] - Avg Loss = 1.0870432299165407 - Correct = 57091 - Accuracy = 0.3836683400200265 - f1 = 0.3745920576679291\n",
      "Start epoch 18\n",
      "[Epoch Train 19] - Avg Loss = 1.0887495607411095 - Correct = 172085 - Accuracy = 0.3854864362357474 - f1 = 0.3852021478698883\n",
      "[Epoch Valid 19] - Avg Loss = 1.0854505105768928 - Correct = 57293 - Accuracy = 0.3850258395328051 - f1 = 0.3849042227726523\n",
      "Start epoch 19\n",
      "[Epoch Train 20] - Avg Loss = 1.0882260349638966 - Correct = 172460 - Accuracy = 0.3863264711812011 - f1 = 0.3860702005581205\n",
      "[Epoch Valid 20] - Avg Loss = 1.085212027114317 - Correct = 57389 - Accuracy = 0.38567098781610587 - f1 = 0.38294049706998795\n",
      "Start epoch 20\n",
      "[Epoch Train 21] - Avg Loss = 1.0876641193182643 - Correct = 172531 - Accuracy = 0.38648551779754037 - f1 = 0.3861157996062303\n",
      "[Epoch Valid 21] - Avg Loss = 1.0856827466731838 - Correct = 57235 - Accuracy = 0.3846360624449776 - f1 = 0.383535031936646\n",
      "Start epoch 21\n",
      "[Epoch Train 22] - Avg Loss = 1.087265350573927 - Correct = 172805 - Accuracy = 0.38709930333101855 - f1 = 0.3868056143403021\n",
      "[Epoch Valid 22] - Avg Loss = 1.0858510374920387 - Correct = 57375 - Accuracy = 0.3855769036914578 - f1 = 0.38311510053856535\n",
      "Start epoch 22\n",
      "[Epoch Train 23] - Avg Loss = 1.0864899753498922 - Correct = 173231 - Accuracy = 0.388053583029054 - f1 = 0.38768035757588687\n",
      "[Epoch Valid 23] - Avg Loss = 1.086345519470123 - Correct = 57072 - Accuracy = 0.38354065442228985 - f1 = 0.3756415171375283\n",
      "Start epoch 23\n",
      "[Epoch Train 24] - Avg Loss = 1.086422230398983 - Correct = 173258 - Accuracy = 0.3881140655451267 - f1 = 0.3877652966858783\n",
      "[Epoch Valid 24] - Avg Loss = 1.0851899987136302 - Correct = 57493 - Accuracy = 0.38636989845634834 - f1 = 0.37864695626555545\n",
      "Start epoch 24\n",
      "[Epoch Train 25] - Avg Loss = 1.0859314105174411 - Correct = 173939 - Accuracy = 0.38963956900607066 - f1 = 0.389339448388023\n",
      "[Epoch Valid 25] - Avg Loss = 1.0852800529780104 - Correct = 57389 - Accuracy = 0.38567098781610587 - f1 = 0.3719730253752664\n",
      "Start epoch 25\n",
      "[Epoch Train 26] - Avg Loss = 1.0854643269553097 - Correct = 174415 - Accuracy = 0.39070585336349994 - f1 = 0.3902855631397682\n",
      "[Epoch Valid 26] - Avg Loss = 1.0854913545700362 - Correct = 57462 - Accuracy = 0.3861615693231991 - f1 = 0.37901999063470804\n",
      "Start epoch 26\n",
      "[Epoch Train 27] - Avg Loss = 1.0851536013801164 - Correct = 174392 - Accuracy = 0.3906543312201788 - f1 = 0.3902824537940419\n",
      "[Epoch Valid 27] - Avg Loss = 1.085478230580521 - Correct = 57360 - Accuracy = 0.3854760992721921 - f1 = 0.3854676447111351\n",
      "Start epoch 27\n",
      "[Epoch Train 28] - Avg Loss = 1.0850023152904773 - Correct = 174636 - Accuracy = 0.39120091395802065 - f1 = 0.39080981673038256\n",
      "[Epoch Valid 28] - Avg Loss = 1.0855373391178489 - Correct = 57265 - Accuracy = 0.38483767128350904 - f1 = 0.3846893482979981\n",
      "Start epoch 28\n",
      "[Epoch Train 29] - Avg Loss = 1.0847592967981046 - Correct = 175027 - Accuracy = 0.3920767903944804 - f1 = 0.39169243362180306\n",
      "[Epoch Valid 29] - Avg Loss = 1.0850107444326937 - Correct = 57410 - Accuracy = 0.3858121140030779 - f1 = 0.38116623917252707\n",
      "Start epoch 29\n",
      "[Epoch Train 30] - Avg Loss = 1.084498481295251 - Correct = 175078 - Accuracy = 0.3921910351470621 - f1 = 0.391819527358422\n",
      "[Epoch Valid 30] - Avg Loss = 1.0852641906598879 - Correct = 57465 - Accuracy = 0.38618173020705227 - f1 = 0.3864355132748552\n",
      "Start epoch 30\n",
      "[Epoch Train 31] - Avg Loss = 1.0843460874614912 - Correct = 175149 - Accuracy = 0.39235008176340136 - f1 = 0.391864048103768\n",
      "[Epoch Valid 31] - Avg Loss = 1.0853992255720104 - Correct = 57467 - Accuracy = 0.38619517079628773 - f1 = 0.3857899783831254\n",
      "Start epoch 31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch Train 32] - Avg Loss = 1.083924655349703 - Correct = 175748 - Accuracy = 0.39369189758293943 - f1 = 0.39334513661712506\n",
      "[Epoch Valid 32] - Avg Loss = 1.0853565430087666 - Correct = 57401 - Accuracy = 0.38575163135151846 - f1 = 0.37165155074626854\n",
      "Start epoch 32\n",
      "[Epoch Train 33] - Avg Loss = 1.0836390617790572 - Correct = 175639 - Accuracy = 0.3934477274254609 - f1 = 0.39300912525645565\n",
      "[Epoch Valid 33] - Avg Loss = 1.0855135552758097 - Correct = 57314 - Accuracy = 0.38516696571977715 - f1 = 0.3819702391384429\n",
      "Start epoch 33\n",
      "[Epoch Train 34] - Avg Loss = 1.0836893042224809 - Correct = 175664 - Accuracy = 0.3935037297551578 - f1 = 0.3931856251538384\n",
      "[Epoch Valid 34] - Avg Loss = 1.0851394446472207 - Correct = 57357 - Accuracy = 0.38545593838833897 - f1 = 0.3747159200507831\n",
      "Start epoch 34\n",
      "[Epoch Train 35] - Avg Loss = 1.0831727583063853 - Correct = 176399 - Accuracy = 0.39515019824824715 - f1 = 0.3946768197043203\n",
      "[Epoch Valid 35] - Avg Loss = 1.0856955330226306 - Correct = 57223 - Accuracy = 0.384555418909565 - f1 = 0.3830830476883919\n",
      "Start epoch 35\n",
      "[Epoch Train 36] - Avg Loss = 1.0830590683932697 - Correct = 176589 - Accuracy = 0.3955758159539437 - f1 = 0.3952078250377277\n",
      "[Epoch Valid 36] - Avg Loss = 1.0849657442071574 - Correct = 57717 - Accuracy = 0.3878752444507167 - f1 = 0.380131772094471\n",
      "Start epoch 36\n",
      "[Epoch Train 37] - Avg Loss = 1.0828834789540243 - Correct = 176656 - Accuracy = 0.3957259021975314 - f1 = 0.3953335086294625\n",
      "[Epoch Valid 37] - Avg Loss = 1.0847571744861422 - Correct = 57607 - Accuracy = 0.38713601204276793 - f1 = 0.38288149984860725\n",
      "Start epoch 37\n",
      "[Epoch Train 38] - Avg Loss = 1.0823937761127402 - Correct = 177100 - Accuracy = 0.39672050357294864 - f1 = 0.39633704274633347\n",
      "[Epoch Valid 38] - Avg Loss = 1.085834558729662 - Correct = 57134 - Accuracy = 0.3839573126885883 - f1 = 0.3644068617844847\n",
      "Start epoch 38\n",
      "[Epoch Train 39] - Avg Loss = 1.082425826015549 - Correct = 177062 - Accuracy = 0.3966353800318093 - f1 = 0.3961677479106222\n",
      "[Epoch Valid 39] - Avg Loss = 1.085338666535408 - Correct = 57356 - Accuracy = 0.38544921809372124 - f1 = 0.38562596256234166\n",
      "Start epoch 39\n",
      "[Epoch Train 40] - Avg Loss = 1.082134596935106 - Correct = 177474 - Accuracy = 0.3975582984252145 - f1 = 0.3972312531545466\n",
      "[Epoch Valid 40] - Avg Loss = 1.085193955170524 - Correct = 57521 - Accuracy = 0.38655806670564435 - f1 = 0.38276231167163804\n",
      "Start epoch 40\n",
      "[Epoch Train 41] - Avg Loss = 1.0821351686475473 - Correct = 177522 - Accuracy = 0.39766582289823255 - f1 = 0.39725150978692514\n",
      "[Epoch Valid 41] - Avg Loss = 1.0851360353435409 - Correct = 57320 - Accuracy = 0.38520728748748345 - f1 = 0.3853366697432941\n",
      "Start epoch 41\n",
      "[Epoch Train 42] - Avg Loss = 1.0818119300956572 - Correct = 177825 - Accuracy = 0.39834457113415916 - f1 = 0.39796303174356745\n",
      "[Epoch Valid 42] - Avg Loss = 1.0856873570898946 - Correct = 57298 - Accuracy = 0.3850594410058937 - f1 = 0.3830371462188967\n",
      "Start epoch 42\n",
      "[Epoch Train 43] - Avg Loss = 1.0816951301803284 - Correct = 177730 - Accuracy = 0.3981317622813109 - f1 = 0.3977123018019908\n",
      "[Epoch Valid 43] - Avg Loss = 1.0850269053377986 - Correct = 57403 - Accuracy = 0.3857650719407539 - f1 = 0.3846275520012876\n",
      "Start epoch 43\n",
      "[Epoch Train 44] - Avg Loss = 1.0816216707708093 - Correct = 177742 - Accuracy = 0.3981586433995654 - f1 = 0.3977409949748496\n",
      "[Epoch Valid 44] - Avg Loss = 1.0852238668620535 - Correct = 57475 - Accuracy = 0.38624893315322945 - f1 = 0.3803292314862869\n",
      "Start epoch 44\n",
      "[Epoch Train 45] - Avg Loss = 1.0816500274071452 - Correct = 177914 - Accuracy = 0.3985439394278802 - f1 = 0.3980871709245355\n",
      "[Epoch Valid 45] - Avg Loss = 1.0852080422644972 - Correct = 57436 - Accuracy = 0.3859868416631385 - f1 = 0.37599414125982583\n",
      "Start epoch 45\n",
      "[Epoch Train 46] - Avg Loss = 1.0814162033413528 - Correct = 178025 - Accuracy = 0.3987925897717345 - f1 = 0.39838919224784636\n",
      "[Epoch Valid 46] - Avg Loss = 1.0871571396715356 - Correct = 56888 - Accuracy = 0.3823041202126301 - f1 = 0.37234553892171757\n",
      "Start epoch 46\n",
      "[Epoch Train 47] - Avg Loss = 1.081144372975334 - Correct = 178672 - Accuracy = 0.40024193006429065 - f1 = 0.3998617597091738\n",
      "[Epoch Valid 47] - Avg Loss = 1.0859466570774645 - Correct = 57305 - Accuracy = 0.3851064830682177 - f1 = 0.37831869336632784\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCH = 100\n",
    "LEARNING_RATE = 10e-6\n",
    "\n",
    "def train_model(training_workspace: str, model_name: str):\n",
    "    cnn_model = I5_CNNet().to(device) # Careful: hard-coded the model here\n",
    "    \n",
    "    #optimizer \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(cnn_model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    # data source (TODO: refactor the sampler to handle both train and test data)\n",
    "    transform = transforms.Compose([transforms.Grayscale(), transforms.ToTensor()])\n",
    "    dataset_folder = os.path.join(training_workspace, 'input/train')\n",
    "    dataset = ImageFolder(dataset_folder, transform=transform)\n",
    "    train_data, valid_data = random_split(dataset, [0.75, 0.25])\n",
    "    train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    valid_loader = DataLoader(valid_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    time_now = int(time.time())\n",
    "    stat = []\n",
    "    \n",
    "    patience = 10\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    no_improvement_count = 0\n",
    "    for epoch in range(EPOCH):\n",
    "        # training\n",
    "        cnn_model.train()\n",
    "        print(f'Start epoch {epoch}')\n",
    "        y_true, y_pred = [], []\n",
    "        train_total_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = cnn_model(inputs)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "            train_total_loss += loss.item()\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "        train_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "        print(f'[Epoch Train {epoch + 1}] - Avg Loss = {train_total_loss / len(train_loader)} - Correct = {train_correct} - Accuracy = {train_correct / train_total} - f1 = {train_f1}')\n",
    "        \n",
    "        # validating\n",
    "        cnn_model.eval()\n",
    "        y_true, y_pred = [], []\n",
    "        val_total_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in valid_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = cnn_model(inputs)\n",
    "                \n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                y_true.extend(labels.cpu().numpy())\n",
    "                y_pred.extend(predicted.cpu().numpy())\n",
    "                val_total_loss += loss.item()\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "            val_f1 = f1_score(y_true, y_pred, average='macro')\n",
    "            print(f'[Epoch Valid {epoch + 1}] - Avg Loss = {val_total_loss / len(valid_loader)} - Correct = {val_correct} - Accuracy = {val_correct / val_total} - f1 = {val_f1}')\n",
    "            \n",
    "        stat.append({\n",
    "            'epoch': epoch,\n",
    "            'train_loss': train_total_loss,\n",
    "            'train_accuracy': train_correct / train_total,\n",
    "            'train_f1': train_f1,\n",
    "            'val_loss': val_total_loss,\n",
    "            'val_accuracy': val_correct / val_total,\n",
    "            'val_f1': val_f1,\n",
    "        })\n",
    "        \n",
    "        # early stopping\n",
    "        if val_total_loss < best_val_loss:\n",
    "            best_val_loss = val_total_loss\n",
    "            best_model_state = cnn_model.state_dict()\n",
    "            no_improvement_count = 0\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': best_model_state,\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, f'{training_workspace}/{model_name}-{time_now}.pth')\n",
    "        else:\n",
    "            no_improvement_count += 1\n",
    "            if no_improvement_count >= patience:\n",
    "                print('Early stopping triggered.')\n",
    "                break\n",
    "            \n",
    "    pd.DataFrame(stat).to_csv(f'{training_workspace}/out-{time_now}.csv', index=False)\n",
    "    \n",
    "\n",
    "# Please check cnn_model variable in train_model() before you run it!\n",
    "train_model('../../../training/nikkei_mid_small_cap/i5-r5-ma50', 'nikkei_mid_small_cap-i5r5ma50')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
